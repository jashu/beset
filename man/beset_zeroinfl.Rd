% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/beset_zeroinfl.R
\name{beset_zeroinfl}
\alias{beset_zeroinfl}
\title{Best Subset Selection for Zero-inflated Count Data Regression}
\usage{
beset_zeroinfl(form, data, test_data = NULL, family = "poisson",
  link = "logit", p_count_max = 10, p_zero_max = 10, n_cores = 2,
  n_folds = 10, n_repeats = 10, seed = 42)
}
\arguments{
\item{form}{A model \code{\link[stats]{formula}}. Note that you cannot
specify a separate model formula for count and zero components as when
calling \code{\link[pscl]{zeroinfl}} directly. Instead use a single formula
that would equal or nest the maximum complexity desired for both components,
and use the \code{p_count_max} and \code{p_zero_max} arguments if you want
to impose differential constraints on the complexity of each component.}

\item{data}{Data frame with the variables in \code{form} and the data
to be used for model fitting.}

\item{test_data}{Optional data frame with the variables in \code{form} and
the data to be used for model validation.}

\item{family}{Character string naming the count model family. Options are
\code{"poisson"} (default), \code{"negbin"}, or \code{"geometric"}. (Note a
log link is always used with the count model).}

\item{link}{Character string naming the link function in the binary
zero-inflation model. Options are \code{"logit"} (default), \code{"probit"},
\code{"cloglog"}, \code{"cauchit"}, or \code{"log"}. (Note a binomial family
is always used with the zero-inflation model).}

\item{p_count_max}{Maximum number of predictors allowed in count model.}

\item{p_zero_max}{Maximum number of predictors allowed in zero model.}

\item{n_cores}{Integer value indicating the number of workers to run in
parallel during subset search and cross-validation. By default, this will
be set to 2. To determine the theoretical maximum number of cores you have
available, see \code{\link[parallel]{detectCores}}, but note that the actual
number of cores available may be less. See
\code{\link[parallel]{parallel-package}} for more information.}

\item{n_folds}{Integer indicating the number of folds to use for
cross-validation.}

\item{n_repeats}{Integer indicating the number of times cross-validation
should be repeated.}

\item{seed}{An integer used to seed the random number generator when
assigning observations to folds.}
}
\value{
A "beset_zeroinfl" object with the following components:
\enumerate{
 \item\describe{
   \item{params}{list of parameters used in function call that will be
   needed to reproduce results}
 }
  \item\describe{
    \item{model_data}{data frame extracted from \code{data} and used to
     identify best subsets.}
 }
 \item\describe{
   \item{stats}{A list of five data frames, each containing metrics
   describing model fits or predictions:
   \describe{\item{count_fit}{a data frame containing fit statistics for every
     possible combination of predictors of count data:
     \describe{
     \item{n_count_pred}{the number of count predictors in model; note that
      the number of predictors for a factor variable corresponds to the
      number of factor levels minus 1}
     \item{count_pred}{rhs of formula for count model}
     \item{aic}{\eqn{-2*log-likelihood + k*npar}, where \eqn{npar} represents
     the number of parameters in the fitted model, and \eqn{k = 2}}
     \item{dev}{twice the difference between the log-likelihoods of the
             saturated and fitted models, multiplied by the scale parameter}
     \item{mae}{mean absolute error}
     \item{mce}{mean cross entropy, estimated as \eqn{-log-likelihood/N},
     where \eqn{N} is the number of observations}
     \item{mse}{mean squared error}
     \item{r2}{R-squared, calculated as \eqn{1 - deviance/null deviance}}}
    }}
   \describe{
   \item{zero_fit}{a data frame containing the same fit statistics described
   for \code{count_fit} but for every possible combination of predictors of
   zeroes vs. non-zeroes (\code{n_zero_pred} and \code{zero_pred} replace
   \code{n_count_pred} and \code{count_pred}, respectively).}}
   \describe{
   \item{fit}{a data frame containing the same fit statistics described for
   \code{count_fit} but for all combinations of the best model for each
   \code{n_count_pred} and the best model for each \code{n_zero_pred} listed
   in \code{count_fit} and \code{zero_fit}, respectively.}}
   \describe{
   \item{cv}{a data frame containing cross-validation statistics for all
    combinations of the best models for each \code{n_count_pred} and
    \code{n_zero_pred} listed in \code{fit}, except AIC is omitted. Each
    metric is followed by its standard error.}}
 \describe{
   \item{test}{if \code{test_data} is provided, a data frame containing
    prediction metrics for the best model for each \code{n_count_pred} and
    \code{n_zero_pred} combination listed in \code{fit} as applied to the
    \code{test_data}.}}
 }}
}
}
\description{
\code{beset_zeroinfl} performs best subset selection using repeated
cross-validation to find the optimal number of predictors for zero-inflated
regression models.
}
\details{
\code{beset_zeroinfl} performs best subset selection for zero-inflated
count models, fitting both a count model (e.g., negative binomial regression)
and zero-inflation model (e.g., logistic regression). Given that there are
two models involved, the search for the best combination of predictors is
not completely exhaustive, which would require fitting \eqn{(2^p)^2} models,
e.g., just 10 predictors have over 1 million possible combinations. Instead,
best subset selection is first performed separately for each of the two
models, using only an intercept term for the other model. This narrows the
search to \eqn{2(2^p) + p^2} models (e.g., 2148 for \eqn{p = 10}): the
best models for each possible number of predictors of the count process
(using a constant to predict the zero process) crossed with the best models
for each possible number of predictors of the zero process (using a constant
to predict the count process). Thus, for every \eqn{m} in \eqn{0, 1, ... p}
best predictors of the count process and every \eqn{n} in \eqn{0, 1, ... p}
best predictors of the zero-inflation process, \code{beset_zeroinfl} uses
\eqn{k}-fold cross-validation to select the model with the \eqn{m * n} number
of predictors that minimizes prediction error, i.e., how well the best models
trained using \eqn{k - 1} folds predict the out-of-fold samples.
}
\section{Cross-validation details}{

When randomly assigning observations to cross-validation folds, responses
with zero values are first allocated to equalize (as much as possible) the
incidence of zero observations across folds. The remaining non-zero values
are then randomly allocated within subgroups based on percentiles to insure
that the folds will also be balanced in terms of the count distribution.

\code{beset_zeroinfl} enforces the "one in ten rule" for each component of
the model with respect to the sample size expected for \eqn{k - 1} folds,
i.e., there must be a minimum of 10 observations of zero across \eqn{k - 1}
folds for every predictor in the zero-inflation model, and there must be
a minimum of 10 observations of non-zero counts across \eqn{k - 1} folds for
every predictor in the count model. \code{beset_zeroinfl} will screen for
this and, if possible, alter your settings for \code{p_zero_max} and/or
\code{p_count_max} to insure an adequate training sample size for all model
fits. If this happens, a warning message will be issued informing you of
the new settings.
}

\section{Warnings}{

\enumerate{
 \item \code{beset_zeroinfl} handles missing data by performing listwise
   deletion. No other options for handling missing data are provided at this
   time. The user is encouraged to deal with missing values prior to running
   this function. A warning message will be issued indicating how much
   data are being deleted.
 \item \code{beset_zeroinfl} is intended for use with additive models only.
   While there is no prohibition against the inclusion of interaction or
   polynomial terms, this practice is strongly discouraged. At best, this
   will result in an inefficient search because \code{beset_zeroinfl}
   performs an exhaustive search over all possible variable subsets,
   including subsets that are hierarchically incomplete, i.e., subsets that
   contain an interaction term but are missing one or more of the subterms
   that comprise it. At worst, it may return one of these hierarchically
   incomplete models as the best model, an undesirable result if one cares
   about interpretability.
 \item \code{beset_zeroinfl} can be very slow and memory intensive.
 Attempting to run with more than 10 variables in the model data frame is not
 recommended.
}
}

\seealso{
\code{\link[caret]{createFolds}}, \code{\link{beset_glm}},
\code{\link[pscl]{zeroinfl}}, \code{\link[base]{set.seed}},
\code{\link{predict_metrics}}
}
